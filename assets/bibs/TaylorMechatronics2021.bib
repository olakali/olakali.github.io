@article{TAYLOR2021102576,
title = {Active learning in robotics: A review of control principles},
journal = {Mechatronics},
volume = {77},
pages = {102576},
year = {2021},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2021.102576},
url = {https://www.sciencedirect.com/science/article/pii/S0957415821000659},
author = {Annalisa T. Taylor and Thomas A. Berrueta and Todd D. Murphey},
keywords = {Active learning, Robotics, Robot control, Learning theory, Perception and sensing, Artificial intelligence},
abstract = {Active learning is a decision-making process. In both abstract and physical settings, active learning demands both analysis and action. This is a review of active learning in robotics, focusing on methods amenable to the demands of embodied learning systems. Robots must be able to learn efficiently and flexibly through continuous online deployment. This poses a distinct set of control-oriented challenges—one must choose suitable measures as objectives, synthesize real-time control, and produce analyses that guarantee performance and safety with limited knowledge of the environment or robot itself. In this work, we survey the fundamental components of robotic active learning systems. We discuss classes of learning tasks that robots typically encounter, measures with which they gauge the information content of observations, and algorithms for generating action plans. Moreover, we provide a variety of examples – from environmental mapping to nonparametric shape estimation – that highlight the qualitative differences between learning tasks, information measures, and control techniques. We conclude with a discussion of control-oriented open challenges, including safety-constrained learning and distributed learning.}
}